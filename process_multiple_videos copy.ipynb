{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.47  Python-3.12.3 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3050, 8192MiB)\n",
      "Setup complete  (32 CPUs, 31.8 GB RAM, 486.0/930.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision.__version__: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import supervision as sv\n",
    "print(\"supervision.__version__:\", sv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"yolov8x.pt\"\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SyntaxWarning: invalid escape sequence '\\P'\n",
      "SyntaxWarning: invalid escape sequence '\\P'\n",
      "SyntaxWarning: invalid escape sequence '\\P'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.3 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.47  Python-3.12.3 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3050, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=scooter_trainning\\Patinetes electricos.v4i.yolov8-obb\\data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'scooter_trainning/Patinetes electricos.v4i.yolov8-obb/data.yaml' error  \nDataset 'scooter_trainning/Patinetes electricos.v4i.yolov8-obb/data.yaml' images not found , missing path 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets\\roboflow\\valid\\images'\nNote dataset download directory is 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets'. You can update this in 'C:\\Users\\ignac\\AppData\\Roaming\\Ultralytics\\settings.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ignac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:514\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    513\u001b[0m }:\n\u001b[1;32m--> 514\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\ignac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py:329\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    328\u001b[0m     m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote dataset download directory is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You can update this in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSETTINGS_YAML\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(m)\n\u001b[0;32m    330\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: \nDataset 'scooter_trainning/Patinetes electricos.v4i.yolov8-obb/data.yaml' images not found ⚠️, missing path 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets\\roboflow\\valid\\images'\nNote dataset download directory is 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets'. You can update this in 'C:\\Users\\ignac\\AppData\\Roaming\\Ultralytics\\settings.yaml'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscooter_trainning\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPatinetes electricos.v4i.yolov8-obb\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ignac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:649\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    647\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\ignac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:129\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Model and Dataset\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ignac\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:518\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'scooter_trainning/Patinetes electricos.v4i.yolov8-obb/data.yaml' error  \nDataset 'scooter_trainning/Patinetes electricos.v4i.yolov8-obb/data.yaml' images not found , missing path 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets\\roboflow\\valid\\images'\nNote dataset download directory is 'C:\\Users\\ignac\\Documents\\ipre_ciclistas\\datasets'. You can update this in 'C:\\Users\\ignac\\AppData\\Roaming\\Ultralytics\\settings.yaml'"
     ]
    }
   ],
   "source": [
    "results = model.train(data='scooter_trainning\\Patinetes electricos.v4i.yolov8-obb\\data.yaml', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fuse()\n",
    "# dict maping class_id to class_name\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "\n",
    "# class_ids of interest - car, motorcycle, bus and truck\n",
    "selected_classes = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from IPython import display\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VARIABLES2\n",
    "import importlib\n",
    "importlib.reload(VARIABLES2)\n",
    "from VARIABLES2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hypotenuse(a, b):\n",
    "  return math.sqrt(a**2 + b**2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoInfoHandler():\n",
    "  def __init__(self) -> None:\n",
    "    self.video_info = None\n",
    "    self.va_params = {}\n",
    "    self.line_zone_annotators = []\n",
    "    self.label_annotator = None\n",
    "    self.trace_annotator = None\n",
    "    self.byte_tracker = None\n",
    "    self.line_zones = [] \n",
    "    pass\n",
    "    \n",
    "  def re_init(self, SOURCE_VIDEO_PATH):\n",
    "    self.video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "    self.init_va_params()\n",
    "    self.init_line_zone_annotators()\n",
    "    self.label_annotator = sv.LabelAnnotator( text_thickness=self.va_params[\"text_thickness\"], text_scale=self.va_params[\"text_scale\"])\n",
    "    self.trace_annotator = sv.TraceAnnotator(thickness=self.va_params[\"thickness\"], trace_length=self.va_params[\"trace_length\"])\n",
    "    self.byte_tracker = sv.ByteTrack(\n",
    "      track_activation_threshold=0.25, lost_track_buffer=30, minimum_matching_threshold=0.8, frame_rate=self.video_info.fps\n",
    "    )\n",
    "    self.init_line_zones()\n",
    "    \n",
    "  def init_va_params(self):\n",
    "    video_default_size = calculate_hypotenuse(1920, 1080)\n",
    "    video_current_size = calculate_hypotenuse(self.video_info.width, self.video_info.height)\n",
    "    proportion = video_current_size / video_default_size\n",
    "    self.va_params = {\n",
    "        \"thickness\": round(THICKNESS_DEFAULT * proportion),\n",
    "        \"text_thickness\": round(TEXT_THICKNESS_DEFAULT * proportion),\n",
    "        \"text_scale\": TEXT_SCALE_DEFAULT * proportion,\n",
    "        \"trace_length\": round(TRACE_LENGTH_DEFAULT * proportion),\n",
    "    }\n",
    "    \n",
    "  def init_line_zone_annotators(self):\n",
    "    self.line_zone_annotators = [sv.LineZoneAnnotator(\n",
    "                thickness=self.va_params[\"thickness\"],\n",
    "                text_thickness=self.va_params[\"text_thickness\"],\n",
    "                text_scale=self.va_params[\"text_scale\"]\n",
    "                )\n",
    "              for _ in range(3)]\n",
    "    \n",
    "  def get_line_zones(self):\n",
    "    line_zones = []\n",
    "    for i in [-1, 0, 1]:\n",
    "        x = self.video_info.width * (1 / 2 + i * 0.15)\n",
    "        line_zones.append(\n",
    "          sv.LineZone(\n",
    "          start=sv.Point( x, 0),\n",
    "          end=sv.Point(x, self.video_info.height)\n",
    "          )\n",
    "        )\n",
    "    return line_zones\n",
    "          \n",
    "  def init_line_zones(self):\n",
    "    new_line_zones = self.get_line_zones()\n",
    "    if self.line_zones:\n",
    "      for i, ex_line in enumerate(self.line_zones):\n",
    "        new_line_zones[i].in_count = ex_line.in_count\n",
    "        new_line_zones[i].out_count = ex_line.out_count\n",
    "    \n",
    "    self.line_zones = new_line_zones\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_video(\n",
    "    source_path: str,\n",
    "    target_path: str,\n",
    "    callback,\n",
    "    stride=1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process a video file by applying a callback function on each frame\n",
    "        and saving the result to a target video file.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): The path to the source video file.\n",
    "        target_path (str): The path to the target video file.\n",
    "        callback (Callable[[np.ndarray, int], np.ndarray]): A function that takes in\n",
    "            a numpy ndarray representation of a video frame and an\n",
    "            int index of the frame and returns a processed numpy ndarray\n",
    "            representation of the frame.\n",
    "\n",
    "    Examples:\n",
    "        ```python\n",
    "        import supervision as sv\n",
    "\n",
    "        def callback(scene: np.ndarray, index: int) -> np.ndarray:\n",
    "            ...\n",
    "\n",
    "        process_video(\n",
    "            source_path=<SOURCE_VIDEO_PATH>,\n",
    "            target_path=<TARGET_VIDEO_PATH>,\n",
    "            callback=callback\n",
    "        )\n",
    "        ```\n",
    "    \"\"\"\n",
    "    source_video_info = sv.VideoInfo.from_video_path(video_path=source_path)\n",
    "    with sv.VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n",
    "        for index, frame in tqdm(enumerate(\n",
    "            sv.get_video_frames_generator(source_path=source_path, stride=stride)\n",
    "        ), desc=\" Video processing\", position=1, leave=False, total=source_video_info.total_frames):\n",
    "            result_frame = callback(frame, index)\n",
    "            sink.write_frame(frame=result_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a043727e702c4accbe7f5847b8cd7f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Videos remaining:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869fe48a25e48758c09805816ec7f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/18032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccb86a424d849ef9b87446a4a007621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/18031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5017c7d140341e392b56181d35f0427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/18032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f39955ef0cb41f98cc2fc1d90d4ac3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/18031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37829074f654a67ac6ad0c76c1b947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/2682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "153 114\n"
     ]
    }
   ],
   "source": [
    "import VARIABLES2\n",
    "import importlib\n",
    "importlib.reload(VARIABLES2)\n",
    "from VARIABLES2 import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "videos_folder = \"3-3\"\n",
    "videos_folder_path = os.path.join(\"full_recordings\", videos_folder)\n",
    "data = [[\"file_name\", \"in\", \"out\"]]\n",
    "\n",
    "prev_in, prev_out = 0, 0\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(\"results\", f\"{videos_folder}.csv\"), \"w\", newline=\"\") as csv_output:\n",
    "  writer = csv.writer(csv_output)\n",
    "  try:\n",
    "    for file_name in tqdm(os.listdir(videos_folder_path), desc=\" Videos remaining\", position=0):\n",
    "      file_path = os.path.join(videos_folder_path, file_name)\n",
    "      vih.re_init(file_path)\n",
    "      process_video(\n",
    "        source_path = file_path,\n",
    "        target_path = TARGET_DUMMY_VIDEO_PATH,\n",
    "        model=model,\n",
    "        selected_classes=selected_classes,\n",
    "        callback=callback,\n",
    "      )\n",
    "      max_in = max(vih.line_zones, key=lambda x: x.in_count)\n",
    "      max_out = max(vih.line_zones, key=lambda x: x.out_count)\n",
    "      \n",
    "      data.append([file_name, max_in.in_count - prev_in, max_out.out_count - prev_out])\n",
    "      prev_in = max_in.in_count\n",
    "      prev_out = max_out.out_count\n",
    "      \n",
    "  except KeyError as e:\n",
    "    print(e)\n",
    "  finally: \n",
    "    writer.writerows(data)\n",
    "    result = subprocess.run(f\"echo {max_in.in_count}, {max_out.out_count} > results/{videos_folder}.txt\", shell=True, capture_output=True, text=True)\n",
    "\n",
    "    # Check if the command was successful\n",
    "    if result.returncode == 0:\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(\"Command failed with error:\")\n",
    "        print(result.stdout)\n",
    "        print(result.stderr)\n",
    "    print(max_in.in_count, max_out.out_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "a, b = 2, 5\n",
    "result = subprocess.run(f\"echo {a} {b} > results/3-2.txt\", shell=True, capture_output=True, text=True)\n",
    "\n",
    "# Check if the command was successful\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Command failed with error:\")\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
