{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.10.0 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce GTX 1650 Ti, 4096MiB)\n",
      "Setup complete âœ… (16 CPUs, 11.4 GB RAM, 434.6/476.1 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision.__version__: 0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import supervision as sv\n",
    "print(\"supervision.__version__:\", sv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"yolov8x.pt\"\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(MODEL)\n",
    "model.fuse()\n",
    "# dict maping class_id to class_name\n",
    "CLASS_NAMES_DICT = model.model.names\n",
    "\n",
    "# class_ids of interest - car, motorcycle, bus and truck\n",
    "selected_classes = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e735449082eb41c6a0e91d8bd610a4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Videos remaining:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa7a2e1260b4906905e1aa1808c9951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedea691ae4542448aa0c5d1eb239456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       " Video processing:   0%|          | 0/365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n"
     ]
    }
   ],
   "source": [
    "import VARIABLES2\n",
    "import importlib\n",
    "importlib.reload(VARIABLES2)\n",
    "from VARIABLES2 import *\n",
    "\n",
    "\n",
    "vih = VideoInfoHandler()\n",
    "\n",
    "def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
    "    # model prediction on single frame and conversion to supervision Detections\n",
    "    results = model(frame, verbose=False, device=torch.device(\"cuda:0\"))[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    # only consider class id from selected_classes define above \n",
    "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
    "    # tracking detections\n",
    "    detections = vih.byte_tracker.update_with_detections(detections)\n",
    "    labels = [\n",
    "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
    "        for confidence, class_id, tracker_id\n",
    "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
    "    ]\n",
    "    annotated_frame = vih.trace_annotator.annotate(\n",
    "        scene=frame.copy(),\n",
    "        detections=detections\n",
    "    )\n",
    "    annotated_frame=vih.label_annotator.annotate(\n",
    "        scene=annotated_frame,\n",
    "        detections=detections,\n",
    "        labels=labels)\n",
    "\n",
    "    # update line counter\n",
    "    for line_zone in vih.line_zones:\n",
    "        line_zone.trigger(detections)\n",
    "    # return frame with box and line annotated result\n",
    "    for i in range(3):\n",
    "        annotated_frame = vih.line_zone_annotators[i].annotate(annotated_frame, line_counter=vih.line_zones[i])\n",
    "    return  annotated_frame\n",
    "\n",
    "\n",
    "videos_folder = \"probando\"\n",
    "videos_folder_path = os.path.join(\"full_recordings\", videos_folder)\n",
    "data = [[\"file_name\", \"in\", \"out\"]]\n",
    "\n",
    "prev_in, prev_out = 0, 0\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(\"results\", f\"{videos_folder}.csv\"), \"w\", newline=\"\") as csv_output:\n",
    "  writer = csv.writer(csv_output)\n",
    "  try:\n",
    "    for file_name in tqdm(os.listdir(videos_folder_path), desc=\" Videos remaining\", position=0):\n",
    "      file_path = os.path.join(videos_folder_path, file_name)\n",
    "      vih.re_init(file_path)\n",
    "      process_video(\n",
    "        source_path = file_path,\n",
    "        target_path = TARGET_DUMMY_VIDEO_PATH,\n",
    "        callback=callback,\n",
    "      )\n",
    "      max_in = max(vih.line_zones, key=lambda x: x.in_count)\n",
    "      max_out = max(vih.line_zones, key=lambda x: x.out_count)\n",
    "      \n",
    "      data.append([file_name, max_in.in_count - prev_in, max_out.out_count - prev_out])\n",
    "      prev_in = max_in.in_count\n",
    "      prev_out = max_out.out_count\n",
    "      \n",
    "  except KeyError as e:\n",
    "    print(e)\n",
    "  finally: \n",
    "    writer.writerows(data)\n",
    "    print(max_in.in_count, max_out.out_count)\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
